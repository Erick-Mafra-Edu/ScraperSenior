# Docker Multi-Worker Deployment Guide

## üöÄ Overview

Sistema de scraping com m√∫ltiplos workers usando Docker e docker-compose, permitindo escalar horizontalmente o processamento de URLs.

**Arquitetura:**
```
docker-compose.workers.yml
‚îú‚îÄ‚îÄ meilisearch (servi√ßo de busca)
‚îú‚îÄ‚îÄ scraper-orchestrator (gerencia workers)
‚îú‚îÄ‚îÄ scraper-worker-001 (process URLs)
‚îú‚îÄ‚îÄ scraper-worker-002 (process URLs)
‚îú‚îÄ‚îÄ scraper-worker-003 (process URLs)
‚îî‚îÄ‚îÄ mcp-server (API de busca)
```

---

## üìã Pr√©-requisitos

- Docker 20.10+
- docker-compose 1.29+
- 2+ GB RAM dispon√≠vel (por worker)
- Acesso a /var/run/docker.sock (para orquestra√ß√£o)

```bash
# Verificar vers√µes
docker --version
docker-compose --version

# Exemplo de sa√≠da esperado:
# Docker version 24.0.0
# docker-compose version v2.15.0
```

---

## üéØ Modos de Execu√ß√£o

### 1. LEGACY (Padr√£o - Scraper √önico)

```bash
# Scraper tradicional sem workers
cd infra/docker
docker-compose up -d scraper meilisearch

# Logs
docker-compose logs -f scraper
```

**Quando usar:**
- Desenvolvimento local
- Scraping leve/r√°pido
- Debugging

---

### 2. ORCHESTRATOR (Gerenciador de Workers)

```bash
# Iniciar com 3 workers (padr√£o)
cd infra/docker
docker-compose -f docker-compose.workers.yml up -d

# Com 5 workers (via vari√°vel de ambiente)
NUM_WORKERS=5 docker-compose -f docker-compose.workers.yml up -d

# Com 10 workers (m√°ximo recomendado)
NUM_WORKERS=10 docker-compose -f docker-compose.workers.yml up -d
```

**Componentes:**
- `scraper-orchestrator`: Gerencia workers via Docker API
- `scraper-worker-*`: M√∫ltiplos containers processando URLs
- `meilisearch`: Indexa√ß√£o centralizada
- `mcp-server`: API de busca

**Quando usar:**
- Produ√ß√£o com scraping em larga escala
- Processamento de 1000+ URLs
- Paralelismo necess√°rio

---

### 3. WORKER (Processador Individual)

Worker √© iniciado automaticamente pelo orchestrator.

```bash
# Iniciar worker manualmente (raro)
SCRAPER_MODE=worker WORKER_ID=1 python infra/docker/docker_entrypoint_workers.py
```

---

## ‚öôÔ∏è Configura√ß√£o

### Via Vari√°veis de Ambiente

```bash
# Vari√°veis principais
export NUM_WORKERS=3
export MEILISEARCH_KEY=seu_token_seguro
export LOG_LEVEL=info
export PYTHONUNBUFFERED=1

# Iniciar
NUM_WORKERS=3 docker-compose -f docker-compose.workers.yml up -d
```

### Via Arquivo .env

```bash
# infra/docker/.env
NUM_WORKERS=3
MEILISEARCH_KEY=seu_token_seguro
LOG_LEVEL=info
MEILI_LOG_LEVEL=info
```

Depois rodar normalmente:

```bash
docker-compose -f docker-compose.workers.yml up -d
```

### Via docker-compose override

```bash
# docker-compose.override.yml (local, n√£o commitar)
version: '3.9'
services:
  scraper-worker:
    deploy:
      replicas: 5  # Sobrescreve padr√£o
```

---

## üìä Escalabilidade Din√¢mica

### Scale Workers via docker-compose

```bash
# Iniciar com 3 workers
docker-compose -f docker-compose.workers.yml up -d --scale scraper-worker=3

# Aumentar para 5 workers
docker-compose -f docker-compose.workers.yml up -d --scale scraper-worker=5

# Reduzir para 2 workers
docker-compose -f docker-compose.workers.yml up -d --scale scraper-worker=2

# Visualizar workers
docker ps | grep scraper-worker
```

### Scale via Docker CLI (program√°tico)

```python
from libs.scrapers.adapters.docker_worker_orchestrator import DockerWorkerOrchestrator

async def scale():
    orchestrator = DockerWorkerOrchestrator()
    
    # Escalar para 5 workers
    workers = await orchestrator.scale_workers(5)
    print(f"‚úÖ Escalado para {len(workers)} workers")
    
    # Coletar estat√≠sticas
    stats = await orchestrator.get_worker_stats()
    print(stats)
```

---

## üìà Monitoramento

### Logs em Tempo Real

```bash
# Logs de todos os servi√ßos
docker-compose -f docker-compose.workers.yml logs -f

# Logs de orchestrator apenas
docker-compose -f docker-compose.workers.yml logs -f scraper-orchestrator

# Logs de um worker espec√≠fico
docker-compose -f docker-compose.workers.yml logs -f scraper-worker

# Logs com timestamp e 50 linhas
docker-compose -f docker-compose.workers.yml logs -f --timestamps --tail=50 scraper-orchestrator
```

### Status dos Containers

```bash
# Verificar status
docker-compose -f docker-compose.workers.yml ps

# Exemplo de sa√≠da:
# NAME                      COMMAND    STATUS
# scraper-orchestrator      python...  Up (healthy)
# scraper-worker-001        python...  Up (healthy)
# scraper-worker-002        python...  Up (healthy)
# scraper-worker-003        python...  Up (healthy)
# meilisearch               ...        Up (healthy)
# mcp-server                ...        Up (healthy)
```

### Healthchecks

```bash
# Verificar sa√∫de do orchestrator
curl http://localhost:8001/health

# Verificar sa√∫de do Meilisearch
curl http://localhost:7700/health

# Verificar sa√∫de do MCP Server
curl http://localhost:8000/health
```

### M√©tricas e Estat√≠sticas

```bash
# Conectar ao container e verificar stats
docker exec senior-docs-scraper-orchestrator python -c "
from libs.scrapers.adapters.docker_worker_orchestrator import DockerWorkerOrchestrator
import asyncio
import json

orchestrator = DockerWorkerOrchestrator()
stats = asyncio.run(orchestrator.get_worker_stats())
print(json.dumps(stats, indent=2, default=str))
"
```

---

## üîÑ Opera√ß√µes Comuns

### Iniciar Sistema Completo

```bash
cd infra/docker

# Com 3 workers (padr√£o)
docker-compose -f docker-compose.workers.yml up -d

# Aguardar healthchecks
sleep 30

# Verificar status
docker-compose -f docker-compose.workers.yml ps
```

### Parar Sistema

```bash
docker-compose -f docker-compose.workers.yml down

# Com limpeza de volumes (dados locais)
docker-compose -f docker-compose.workers.yml down -v
```

### Reiniciar Workers

```bash
# Reiniciar todos
docker-compose -f docker-compose.workers.yml restart scraper-worker

# Reiniciar worker espec√≠fico
docker-compose -f docker-compose.workers.yml restart scraper-worker_1
```

### Verificar Logs de Erro

```bash
# Logs dos √∫ltimos 100 linhas com erro
docker-compose -f docker-compose.workers.yml logs --tail=100 scraper-worker | grep -i error

# Logs com contexto (5 linhas antes/depois)
docker-compose -f docker-compose.workers.yml logs scraper-worker | grep -C 5 -i error
```

### Reconstruir Imagem

```bash
# Se mudou c√≥digo
docker-compose -f docker-compose.workers.yml build

# Force rebuild sem cache
docker-compose -f docker-compose.workers.yml build --no-cache

# Depois rodar
docker-compose -f docker-compose.workers.yml up -d
```

---

## üõ°Ô∏è Troubleshooting

### Problema: "Cannot connect to Docker daemon"

**Causa:** Docker n√£o est√° rodando ou socket inacess√≠vel

```bash
# Solu√ß√£o 1: Iniciar Docker
sudo systemctl start docker

# Solu√ß√£o 2: Verificar permiss√µes
ls -la /var/run/docker.sock

# Solu√ß√£o 3: Adicionar usu√°rio ao grupo docker
sudo usermod -aG docker $USER
newgrp docker
```

### Problema: "Out of memory"

**Causa:** Muitos workers ou mem√≥ria insuficiente

```bash
# Ver uso de mem√≥ria
docker stats

# Reduzir workers
docker-compose -f docker-compose.workers.yml up -d --scale scraper-worker=2

# Ou aumentar recursos Docker
# Docker Desktop ‚Üí Settings ‚Üí Resources ‚Üí Memory (aumentar para 4+ GB)
```

### Problema: "Worker container keeps restarting"

**Causa:** Erro na inicializa√ß√£o do worker

```bash
# Ver logs de erro
docker-compose -f docker-compose.workers.yml logs scraper-worker

# Logs detalhados (√∫ltimas 50 linhas)
docker logs -f --tail=50 $(docker ps -q -f status=running -f ancestor=senior-docs-scraper:latest)

# Verificar healthcheck
docker inspect senior-docs-worker-001 | grep -A 20 '"Health"'
```

### Problema: "Orchestrator cannot reach workers"

**Causa:** Rede Docker n√£o configurada corretamente

```bash
# Verificar rede
docker network ls
docker network inspect senior-docs

# Testar conectividade
docker exec senior-docs-scraper-orchestrator ping scraper-worker-001

# Remover e recri–∞—Ä rede
docker-compose -f docker-compose.workers.yml down -v
docker network rm senior-docs
docker-compose -f docker-compose.workers.yml up -d
```

### Problema: "Meilisearch service unhealthy"

**Causa:** Tempo de startup insuficiente ou recurso indispon√≠vel

```bash
# Verificar logs do Meilisearch
docker-compose -f docker-compose.workers.yml logs meilisearch

# Aumentar timeout de healthcheck
# Editar docker-compose.workers.yml:
# healthcheck:
#   start_period: 15s  # aumentar de 5s

# Aumentar volume do Meilisearch
docker volume ls
du -sh /var/lib/docker/volumes/*/meilisearch_data
```

---

## üöÄ Otimiza√ß√µes

### Resource Limits

```yaml
# docker-compose.workers.yml
scraper-worker:
  deploy:
    resources:
      limits:
        cpus: '1'          # 1 CPU por worker
        memory: 1G         # 1GB por worker
      reservations:
        cpus: '0.5'        # Reserve pelo menos 0.5 CPU
        memory: 512M       # Reserve pelo menos 512MB
```

### Network Optimization

```yaml
# Use host network (mais r√°pido, menos isolamento)
scraper-orchestrator:
  network_mode: host

# Ou configure custom driver
networks:
  senior-docs:
    driver: bridge
    driver_opts:
      com.docker.network.driver.mtu: 1500
```

### Storage Optimization

```bash
# Usar tmpfs para dados tempor√°rios
# docker-compose.workers.yml
scraper-worker:
  tmpfs:
    - /tmp
    - /var/tmp

# Limpar imagens n√£o usadas
docker image prune -a --filter "until=72h"

# Limpar volumes n√£o usados
docker volume prune --filter "label!=keep"
```

---

## üìö Arquivos Relacionados

- `infra/docker/docker-compose.workers.yml` - Compose com multi-worker
- `infra/docker/docker_entrypoint_workers.py` - Entrypoint para orchestrator/worker
- `libs/scrapers/adapters/docker_worker_orchestrator.py` - Orquestrador Docker
- `libs/scrapers/adapters/playwright_worker_pool.py` - Pool de workers em-processo

---

## üéØ Checklist de Deploy

- [ ] Verificar vers√µes de Docker/Compose
- [ ] Configurar vari√°veis de ambiente (.env)
- [ ] Build das imagens (docker-compose build)
- [ ] Iniciar servi√ßos (docker-compose up -d)
- [ ] Aguardar healthchecks (30-60s)
- [ ] Verificar status (docker-compose ps)
- [ ] Verificar logs (docker-compose logs -f)
- [ ] Testar endpoints (curl http://localhost:8001/health)
- [ ] Monitorar recursos (docker stats)
- [ ] Coletar m√©tricas ap√≥s conclus√£o

---

## üîó Refer√™ncias

- [Docker Compose Documentation](https://docs.docker.com/compose/)
- [Docker Python SDK](https://docker-py.readthedocs.io/)
- [PlaywrightWorkerPool Guide](./multi_worker_scraping.md)
- [Meilisearch Docker Setup](https://docs.meilisearch.com/learn/what_is_meilisearch/overview.html)
