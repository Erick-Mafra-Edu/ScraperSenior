# CI/CD Pipeline Configuration

## VisÃ£o Geral

Este pipeline automÃ¡tico valida, testa e garante a qualidade do cÃ³digo antes de qualquer deploy.

### Componentes do Pipeline

1. **Teste de Dados do Scraper** (`tests/test_scraper.py`)
   - ValidaÃ§Ã£o de estrutura JSONL
   - VerificaÃ§Ã£o de tÃ­tulos
   - ValidaÃ§Ã£o de URLs
   - ConsistÃªncia de mÃ³dulos
   - Estrutura de breadcrumbs
   - Encoding UTF-8

2. **Teste de Meilisearch** (`tests/test_meilisearch.py`)
   - ConexÃ£o com servidor
   - ExistÃªncia de Ã­ndices
   - Contagem de documentos
   - Funcionalidade de busca
   - ValidaÃ§Ã£o de campos
   - Busca por mÃ³dulo com filtros

3. **Teste de MCP Server** (`tests/test_mcp_server.py`)
   - Health check
   - Endpoint de estatÃ­sticas
   - Endpoint de ferramentas
   - ConexÃ£o com Meilisearch
   - Endpoint de busca
   - Chamada de ferramentas

### Como Executar

#### Python (Multiplataforma)
```bash
python run_ci_pipeline.py
```

#### PowerShell (Windows)
```powershell
# Executar pipeline completo
.\ci_pipeline.ps1 -Action Full

# Apenas testes
.\ci_pipeline.ps1 -Action RunTests

# Apenas Docker
.\ci_pipeline.ps1 -Action Docker

# Apenas validaÃ§Ã£o de dados
.\ci_pipeline.ps1 -Action ValidateData

# Ver relatÃ³rio
.\ci_pipeline.ps1 -Action Report
```

#### Bash (Linux/Mac)
```bash
python3 run_ci_pipeline.py
```

### Fluxo de ExecuÃ§Ã£o

```
INÃCIO
  â†“
[1] Infraestrutura OK?
    â”œâ”€ Sim â†’ Continuar
    â””â”€ NÃ£o â†’ Aviso (continua mesmo assim)
  â†“
[2] Validar Dados do Scraper
    â”œâ”€ JSONL vÃ¡lido?
    â”œâ”€ TÃ­tulos OK?
    â”œâ”€ URLs OK?
    â””â”€ Encoding OK?
  â†“
[3] Testar Meilisearch
    â”œâ”€ ConexÃ£o OK?
    â”œâ”€ Ãndice existe?
    â”œâ”€ Documentos carregados?
    â””â”€ Busca funciona?
  â†“
[4] Testar MCP Server
    â”œâ”€ Server healthy?
    â”œâ”€ Stats OK?
    â”œâ”€ Busca funciona?
    â””â”€ Ferramentas acessÃ­veis?
  â†“
[5] Gerar RelatÃ³rio
    â”œâ”€ JSON com resultados
    â””â”€ SumÃ¡rio visual
  â†“
FIM
```

### CritÃ©rios de Sucesso

| Teste | CritÃ©rio | AÃ§Ã£o se Falhar |
|-------|----------|---|
| TÃ­tulos | â‰¥ 90% sucesso | Reexecutar scraper |
| URLs | 100% vÃ¡lidas | Validar origem dos dados |
| MÃ³dulos | â‰¥ 1 encontrado | Verificar scraped docs |
| Meilisearch | Conectado e Ã­ndice existe | Reiniciar Docker |
| MCP Health | Status = healthy | Verificar logs |
| Busca | â‰¥ 1 resultado | Reindexar dados |

### IntegraÃ§Ã£o com AlteraÃ§Ãµes de CÃ³digo

#### Pre-commit Hook (Git)
```bash
#!/bin/bash
# .git/hooks/pre-commit

python run_ci_pipeline.py
if [ $? -ne 0 ]; then
    echo "âŒ Testes falharam. Commit bloqueado."
    exit 1
fi
```

#### GitHub Actions (Opcional)
```yaml
name: CI/CD Pipeline
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    services:
      meilisearch:
        image: getmeili/meilisearch:v1.11.0
      mcp-server:
        build: .
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
      - run: python run_ci_pipeline.py
```

### RelatÃ³rio de SaÃ­da

O pipeline gera um arquivo `test_report.json` com:

```json
{
  "timestamp": "2024-01-22T10:30:45.123456",
  "tests": {
    "Scraper Data Validation": {
      "passed": true,
      "returncode": 0
    },
    "Meilisearch Tests": {
      "passed": true,
      "returncode": 0
    },
    "MCP Server Tests": {
      "passed": true,
      "returncode": 0
    }
  },
  "summary": {
    "total_tests": 3,
    "passed": 3,
    "failed": 0,
    "success_rate": "100.0%",
    "status": "SUCCESS âœ…"
  }
}
```

### Troubleshooting

#### Testes falhando apÃ³s alteraÃ§Ãµes

1. **Verificar logs completos**
   ```bash
   docker-compose logs meilisearch | tail -50
   docker-compose logs mcp-server | tail -50
   ```

2. **Limpar cache e reconstruir**
   ```bash
   docker-compose down -v
   docker-compose up -d --build
   python run_ci_pipeline.py
   ```

3. **Reindexar dados**
   ```bash
   python index_meilisearch.py
   python run_ci_pipeline.py
   ```

### MÃ©tricas Rastreadas

- âœ… Taxa de sucesso dos testes
- â±ï¸ Tempo de execuÃ§Ã£o do pipeline
- ğŸ“Š Documentos indexados
- ğŸ” TÃ­tulos capturados com sucesso
- ğŸŒ URLs validadas
- ğŸ“¦ MÃ³dulos descobertos
- ğŸ”— Integridade de links

### PrÃ³ximos Passos

1. [ ] Implementar pre-commit hooks
2. [ ] Configurar GitHub Actions
3. [ ] Adicionar anÃ¡lise de cobertura
4. [ ] Implementar performance benchmarks
5. [ ] Alertas automÃ¡ticos para falhas
6. [ ] Dashboard de mÃ©tricas

