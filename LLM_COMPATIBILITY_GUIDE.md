# Compatibilidade com LLM/Open WebUI - DocumentaÃ§Ã£o Completa

## ğŸ¯ Objetivo

O servidor MCP HTTP agora foi otimizado para integraÃ§Ã£o perfeita com agentes de IA (LLMs) no Open WebUI, fornecendo uma interface REST simples e schemas estruturados.

---

## ğŸš€ Arquitetura para LLM

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Open WebUI    â”‚
â”‚   + LLM Agent   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  REST API       â”‚ â† Simple HTTP GET requests
â”‚  (/api/*)       â”‚   Schemas well-defined
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ MCP HTTP Server â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Meilisearch     â”‚
â”‚ Backend         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š Endpoints REST Otimizados para LLM

### 1. **GET /api/search** - Busca Inteligente (Principal)

**Uso pelo LLM:**
- Responde "como faÃ§o X?" â†’ busca por X
- Sugere melhorias de query baseado em estratÃ©gia
- Refina buscas com /api/document/{id} se necessÃ¡rio

```bash
# Exemplo
GET /api/search?query=configurar+ambiente&strategy=auto&limit=5
```

**Response:**
```json
{
  "status": "success",
  "query": "configurar ambiente",
  "parsed_query": "\"configurar ambiente\"",
  "strategy": "auto",
  "count": 3,
  "results": [
    {
      "id": "doc_123",
      "title": "Configurar Ambiente Local",
      "url": "https://...",
      "module": "Help Center",
      "summary": "Guia passo a passo para...",
      "relevance_score": 0.95
    }
  ]
}
```

**Por que Ã© bom para LLM:**
- âœ… `relevance_score` ajuda LLM a selecionar melhores resultados
- âœ… `summary` Ã© curto (LLM usa para contexto)
- âœ… `id` permite GET /api/document/{id} para conteÃºdo completo
- âœ… `parsed_query` mostra como a busca foi refinada

---

### 2. **GET /api/modules** - ExploraÃ§Ã£o de Contexto

**Uso pelo LLM:**
- Esclarecer qual mÃ³dulo o usuÃ¡rio quer
- Sugerir mÃ³dulos relevantes
- Entender categorias disponÃ­veis

```bash
GET /api/modules
```

**Response:**
```json
{
  "status": "success",
  "total_modules": 12,
  "modules": [
    {
      "name": "Help Center",
      "doc_count": 450,
      "description": "Guias e dÃºvidas frequentes"
    },
    {
      "name": "Release Notes",
      "doc_count": 85,
      "description": "HistÃ³rico de versÃµes"
    }
  ]
}
```

---

### 3. **GET /api/modules/{module_name}** - Listar Docs do MÃ³dulo

**Uso pelo LLM:**
- Navegar documentos de uma categoria especÃ­fica
- Explorar tÃ³picos disponÃ­veis
- Contexto para responder perguntas sobre um domÃ­nio

```bash
GET /api/modules/Help%20Center?limit=20
```

---

### 4. **GET /api/document/{document_id}** - ConteÃºdo Completo â­ NOVO

**Uso pelo LLM:**
- ApÃ³s busca inicial, obter texto completo
- Processar exemplos de cÃ³digo
- Gerar respostas mais precisas

```bash
GET /api/document/doc_123
```

**Response:**
```json
{
  "status": "success",
  "document": {
    "id": "doc_123",
    "title": "Configurar Ambiente Local",
    "url": "https://...",
    "module": "Help Center",
    "content": "...conteÃºdo HTML completo...",
    "metadata": {
      "last_updated": "2026-02-05",
      "word_count": 2500,
      "author": "Senior Docs"
    }
  }
}
```

**Por que Ã© essencial:**
- âœ… LLM pode ler contexto completo
- âœ… Verifica informaÃ§Ãµes antes de responder
- âœ… Encontra exemplos de cÃ³digo
- âœ… Valida informaÃ§Ãµes

---

### 5. **GET /api/stats** - ExploraÃ§Ã£o de Capacidades

**Uso pelo LLM:**
- Informar ao usuÃ¡rio capacidades da base
- Validar dados disponÃ­veis
- Diagnosticar problemas

---

## ğŸ“ Schemas Estruturados (Novo)

### DocumentSummary â­ NOVO
Resultado otimizado para LLM em buscas:
```json
{
  "id": "doc_id",
  "title": "TÃ­tulo",
  "url": "https://...",
  "module": "Category",
  "summary": "Resumo conciso",
  "relevance_score": 0.95
}
```

### Document â­ NOVO
Documento completo com metadados:
```json
{
  "id": "doc_id",
  "title": "TÃ­tulo",
  "url": "https://...",
  "module": "Category",
  "content": "ConteÃºdo HTML completo",
  "metadata": {
    "last_updated": "2026-02-05",
    "word_count": 2500,
    "author": "Source"
  }
}
```

### SearchResult â­ NOVO
Resposta estruturada de /api/search:
```json
{
  "status": "success",
  "query": "termo",
  "parsed_query": "\"termo\"",
  "strategy": "auto",
  "module_filter": null,
  "count": 5,
  "results": [DocumentSummary]
}
```

### ModuleList â­ NOVO
Resposta estruturada de /api/modules:
```json
{
  "status": "success",
  "total_modules": 12,
  "modules": [ModuleInfo]
}
```

### DocumentationStats â­ NOVO
Resposta estruturada de /api/stats:
```json
{
  "total_documents": 10456,
  "total_modules": 12,
  "indexed_date": "2026-02-05",
  "index_size": "45.3 MB",
  "languages": ["pt-BR", "en"],
  "last_update": "2026-02-05T14:30:00Z"
}
```

---

## ğŸ§  PadrÃ£o de Uso Recomendado para LLM

### Pergunta do UsuÃ¡rio: "Como configuro LSP?"

**1ï¸âƒ£ Busca Inicial (RÃ¡pida)**
```bash
GET /api/search?query=configurar+LSP&strategy=auto&limit=5
```
â†’ Retorna 5 DocumentSummaries com scores

**2ï¸âƒ£ ValidaÃ§Ã£o (Opcional)**
Se `relevance_score < 0.7`, refina:
```bash
GET /api/search?query=LSP&strategy=quoted&limit=10
```

**3ï¸âƒ£ Contexto Completo (Se NecessÃ¡rio)**
```bash
GET /api/document/doc_123
```
â†’ LÃª conteÃºdo completo para responder com precisÃ£o

**4ï¸âƒ£ ExploraÃ§Ã£o de MÃ³dulos (Se Incerto)**
```bash
GET /api/modules
```
â†’ Entende contextos disponÃ­veis

---

## ğŸ”‘ EstratÃ©gias de Query para LLM

O LLM pode escolher a estratÃ©gia baseado no tipo de pergunta:

### `strategy=auto` (Recomendado)
- Multi-palavra? â†’ `quoted` (busca exata)
- Uma palavra? â†’ passa como-estÃ¡
- **Uso:** 90% das buscas

### `strategy=quoted`
- ForÃ§a busca de frase exata
- **Uso:** "um padrÃ£o especÃ­fico" ou "um termo tÃ©cnico"

### `strategy=and`
- ForÃ§a presenÃ§a de todos os termos
- **Uso:** "conceitos relacionados mas nÃ£o necessariamente juntos"

---

## ğŸ“Š MÃ©tricas de Qualidade para LLM

```json
{
  "relevance_score": 0.95,      // 0-1: confianÃ§a
  "word_count": 2500,            // contexto size
  "last_updated": "2026-02-05",  // freshness
  "language": "pt-BR",           // relevÃ¢ncia idioma
  "module": "Help Center"        // categoria
}
```

LLM pode usar isso para:
- âœ… Priorizar resultados
- âœ… Indicar confianÃ§a ao usuÃ¡rio
- âœ… Descartar documentos desatualizados
- âœ… Preferir idiomas do usuÃ¡rio

---

## ğŸš¦ Fluxo Recomendado no Open WebUI

```
User Message
    â†“
LLM Request: GET /api/search
    â†“
Parse 5 DocumentSummaries
    â†“
Score > 0.8? â”€NOâ†’ Try /api/search com strategy diferente
    â†“ YES
Get /api/document/{top_id}
    â†“
Read full content
    â†“
Generate response com citations
    â†“
Return to User
```

---

## âœ… Checklist de Compatibilidade LLM

- âœ… REST API simples (GET, sem JSON-RPC)
- âœ… Schemas estruturados e documentados
- âœ… IDs para referÃªncia cruzada (doc_id)
- âœ… Scores de relevÃ¢ncia
- âœ… Resumos concisos
- âœ… ConteÃºdo completo acessÃ­vel
- âœ… CORS habilitado
- âœ… 3 estratÃ©gias de query
- âœ… ExploraÃ§Ã£o de mÃ³dulos
- âœ… Metadados (data, autor, etc)

---

## ğŸ”§ Exemplo de IntegraÃ§Ã£o (PseudocÃ³digo)

```python
class SeniorDocsLLMTool:
    def search(self, query: str, module: str = None, strategy: str = "auto"):
        """Busca documentaÃ§Ã£o e retorna summaries"""
        response = requests.get(
            f"http://localhost:8000/api/search",
            params={"query": query, "strategy": strategy, "module": module}
        )
        return response.json()["results"]
    
    def get_full_document(self, doc_id: str):
        """ObtÃ©m documento completo para anÃ¡lise"""
        response = requests.get(f"http://localhost:8000/api/document/{doc_id}")
        return response.json()["document"]
    
    def list_modules(self):
        """Lista mÃ³dulos para contexto"""
        response = requests.get("http://localhost:8000/api/modules")
        return response.json()["modules"]
    
    def answer_question(self, question: str):
        """Pipeline completo LLM"""
        # 1. Buscar
        results = self.search(question)
        
        # 2. Validar
        if not results or results[0]["relevance_score"] < 0.7:
            results = self.search(question, strategy="quoted")
        
        # 3. Contexto
        best_doc = self.get_full_document(results[0]["id"])
        
        # 4. Responder
        response = llm.generate(
            context=best_doc["content"],
            question=question,
            citations=[r["url"] for r in results[:3]]
        )
        return response
```

---

## ğŸ“– PrÃ³ximos Passos

1. **Implementar GET /api/document/{document_id}** no servidor
   - Requer GET do Meilisearch ou cache local
   - Retorna Document schema completo

2. **Testar com Open WebUI**
   - Configurar como ferramenta customizada
   - Validar parsing de responses
   - Medir performance de query

3. **Refinamentos Opcionais**
   - POST /api/search com JSON body (queries complexas)
   - Response caching (mÃ³dulos, stats)
   - Rate limiting por IP/API-key
   - Logging de queries (analytics)

4. **DocumentaÃ§Ã£o para UsuÃ¡rios**
   - Guia de setup no Open WebUI
   - Exemplos de prompts
   - Best practices

---

## ğŸ¯ ConclusÃ£o

O servidor agora oferece:
- âœ… Interface REST simples para LLMs
- âœ… Schemas bem-definidos e documentados
- âœ… IDs para referÃªncia cruzada
- âœ… Scores de qualidade para priorizaÃ§Ã£o
- âœ… Acesso a conteÃºdo completo
- âœ… ExploraÃ§Ã£o de categorias
- âœ… EstratÃ©gias de query flexÃ­veis

**Resultado:** IntegraÃ§Ã£o perfeita com Open WebUI como ferramenta de IA IA para responder perguntas sobre documentaÃ§Ã£o Senior com precisÃ£o e contexto.
