# Changelog

## [2.1.0] - 2026-01-30 - Multi-Worker Support

### üöÄ Novas Funcionalidades

#### Multi-Worker In-Process (Playwright)
- **PlaywrightWorkerPool**: Novo adapter para scraping paralelo com m√∫ltiplas p√°ginas Playwright
- **IBrowserWorkerPool**: Nova interface (port) para gerenciar pool de workers
- **asyncio.Semaphore**: Limite inteligente de concorr√™ncia
- **asyncio.Queue**: Distribui√ß√£o de URLs entre workers
- **Retry autom√°tico**: Tentativas com exponential backoff
- **Logging detalhado**: Rastreamento de progresso por worker

#### Docker Multi-Worker Orchestration
- **DockerWorkerOrchestrator**: Novo adapter para orquestra√ß√£o de m√∫ltiplos containers
- **docker-compose.workers.yml**: Composi√ß√£o com suporte a multiple workers escal√°veis
- **docker_entrypoint_workers.py**: Entrypoint inteligente (orchestrator/worker/legacy modes)
- **Dockerfile atualizado**: Suporte a 3 modos de execu√ß√£o via SCRAPER_MODE
- **Dockerfile.worker**: Vers√£o otimizada para workers
- **build.sh / build.bat**: Scripts de build para facilitar

#### 3 Modos de Execu√ß√£o
- **LEGACY**: Scraper √∫nico (compat√≠vel com v1.x) - modo padr√£o
- **ORCHESTRATOR**: Gerencia m√∫ltiplos worker containers via Docker API
- **WORKER**: Processa URLs da fila do orchestrator

#### Configura√ß√£o
- Se√ß√£o `concurrency` em `scraper_config.json`:
  - `num_workers`: N√∫mero de p√°ginas paralelas (default: 3)
  - `enable_worker_pool`: Ativar/desativar feature
  - `max_urls_per_worker`: Limite de URLs por worker
  - `worker_timeout_ms`: Timeout para opera√ß√µes
  - `fallback_to_sequential`: Voltar para sequencial em caso de erro

#### Domain Updates
- `Document` agora rastreia metadata de worker:
  - `processed_by_worker`: ID do worker que processou
  - `scraping_duration_seconds`: Dura√ß√£o do scraping

### üìä Performance
- **In-Process**: 2-3x mais r√°pido com 3 workers Playwright (~1-2 URLs/s por worker)
- **Docker**: Escala horizontal com m√∫ltiplos containers (4.3x mais r√°pido com 5 workers)
- **Memory overhead**: ~500MB por worker in-process, ~1GB por container Docker

### üìö Documenta√ß√£o
- `docs/guides/multi_worker_scraping.md`: Guia completo do in-process worker pool
- `docs/guides/docker_multi_worker.md`: Guia de deployment Docker multi-worker
- `infra/docker/README.md`: Docker setup e modes
- `infra/docker/MULTI_WORKER_QUICKSTART.md`: Quick start Docker
- `examples/worker_pool_usage.py`: Exemplos pr√°ticos de uso
- Testes unit√°rios em `tests/unit/adapters/` (15 tests, 100% passing)

### üê≥ Docker Support
- **Dockerfile**: Atualizado com support para 3 modos
- **Dockerfile.worker**: Vers√£o leve para workers
- **docker-compose.workers.yml**: Composi√ß√£o escal√°vel
- **build.sh / build.bat**: Scripts de build

### üîß Arquitetura Hexagonal
- Novo port: `libs/scrapers/ports/browser_worker_pool.py` (IBrowserWorkerPool)
- Novo adapter: `libs/scrapers/adapters/playwright_worker_pool.py` (in-process)
- Novo adapter: `libs/scrapers/adapters/docker_worker_orchestrator.py` (Docker)
- Implementa√ß√µes reutiliz√°veis para qualquer scraper
- 100% retrocompat√≠vel, sem breaking changes

---

## [2.0.0] - 2026-01-30 - Refatora√ß√£o Completa (Monorepo)

### üèóÔ∏è Arquitetura
- **BREAKING**: Migra√ß√£o completa para estrutura monorepo
- Nova organiza√ß√£o: `apps/`, `libs/`, `scripts/`, `docs/`, `data/`, `infra/`, `tests/`
- Separa√ß√£o clara entre aplica√ß√µes execut√°veis e bibliotecas reutiliz√°veis
- Consolida√ß√£o de 60+ arquivos markdown em estrutura organizada

### üìÅ Estrutura do Projeto
**Apps (Aplica√ß√µes execut√°veis)**:
- `apps/scraper/` - Scrapers principal (unificado + modular)
- `apps/mcp-server/` - MCP Server para busca
- `apps/zendesk/` - Integra√ß√£o Zendesk/Suporte Senior

**Libs (Bibliotecas compartilhadas)**:
- `libs/scrapers/` - Scrapers base reutiliz√°veis
- `libs/indexers/` - Indexadores (local JSONL + Meilisearch)
- `libs/pipelines/` - Data pipelines
- `libs/utils/` - Utilidades compartilhadas

**Scripts (Utilit√°rios)**:
- `scripts/analysis/` - Scripts de an√°lise
- `scripts/indexing/` - Scripts de indexa√ß√£o manual
- `scripts/fixes/` - Debug e corre√ß√µes
- `scripts/queries/` - Consultas e verifica√ß√µes

**Dados**:
- `data/scraped/` - Dados extra√≠dos (estruturado, unified, zendesk)
- `data/indexes/` - √çndices JSONL
- `data/metadata/` - Metadados

**Infraestrutura**:
- `infra/docker/` - Dockerfiles e docker-compose
- `infra/ci/` - CI/CD pipelines

**Documenta√ß√£o**:
- `docs/guides/` - Guias de uso
- `docs/architecture/` - Decis√µes de arquitetura
- `docs/api/` - Documenta√ß√£o de API

### üßπ Limpeza
- Removidos 60+ arquivos markdown da raiz
- Consolidados relat√≥rios hist√≥ricos neste CHANGELOG
- Removidas pastas duplicadas (docs_structured/)
- Organizados scripts dispersos em categorias

### üìù Hist√≥rico Consolidado (v1.x)
Abaixo, consolida√ß√£o dos principais eventos e entregas das vers√µes anteriores:

#### Release Notes & Melhorias (Jan 2026)
- Implementado scraping de notas de vers√£o com √¢ncoras (#vers√£o.htm)
- Suporte a m√∫ltiplos m√≥dulos Senior ERP X
- Descoberta autom√°tica de URLs de release notes

#### MCP Server (Jan 2026)
- MCP Server com 4 ferramentas: search_docs, list_modules, get_module_docs, get_stats
- Integra√ß√£o com Claude Desktop
- Testes automatizados MCP
- Docker support para MCP Server

#### Pipeline & CI/CD (Jan 2026)
- Pipeline CI/CD completo (ci_pipeline.ps1)
- Valida√ß√£o de schemas
- Testes automatizados de scraper e MCP
- Docker orchestration

#### Fixes & Debug (Jan 2026)
- Corre√ß√£o de t√≠tulos truncados
- Fix em par√¢metros do Copilot
- Debug de scraping com logs detalhados
- Valida√ß√£o de indexa√ß√£o

#### Zendesk Integration (Jan 2026)
- API Zendesk modular
- Suporte Senior API integration
- Adapter pattern para m√∫ltiplas fontes

### üîß Breaking Changes
- Paths alterados: c√≥digo movido de `src/` para `apps/` e `libs/`
- Configs movidos para `apps/*/config/`
- Dados movidos para `data/`
- Imports precisam ser atualizados
- Docker volumes precisam apontar para novos paths

### üìö Migra√ß√£o
Para migrar c√≥digo existente:
1. Atualizar imports: `from src.X import Y` ‚Üí `from apps.X import Y` ou `from libs.X import Y`
2. Atualizar paths de config: `./config.json` ‚Üí `./apps/*/config/*.json`
3. Atualizar paths de dados: `./docs_*` ‚Üí `./data/scraped/*`
4. Revisar docker-compose.yml volumes

---

## [1.0.0] - 2026-01-20

### ‚ú® Features
- ‚úÖ Scraper unificado para MadCap Flare e Astro
- ‚úÖ Extra√ß√£o hier√°rquica com breadcrumb completo
- ‚úÖ Organiza√ß√£o autom√°tica em estrutura de pastas
- ‚úÖ Gera√ß√£o de JSONL para Meilisearch
- ‚úÖ Metadados completos e estat√≠sticas
- ‚úÖ Docker compose ready
- ‚úÖ Setup autom√°tico

### üßπ Cleanup
- ‚ùå Removidos 40+ arquivos de teste antigos
- ‚ùå Removidas 8 pastas de documenta√ß√£o obsoleta
- ‚ùå Removido c√≥digo legado (Flask API, Scrapy, etc)
- ‚ùå Simplificado docker-compose.yml
- ‚ùå Atualizado requirements.txt (apenas essenciais)

### üìù Documentation
- ‚úÖ README.md completamente reescrito
- ‚úÖ README_SCRAPER.md com detalhes de uso
- ‚úÖ LIMPEZA_CONCLUIDA.md com sum√°rio
- ‚úÖ .env.example com configura√ß√µes padr√£o

### üõ†Ô∏è Infrastructure
- ‚úÖ docker-compose.yml simplificado
- ‚úÖ Dockerfile otimizado
- ‚úÖ tools/setup.py para instala√ß√£o r√°pida
- ‚úÖ tools/maintenance.py para limpeza

### üìä Results
- 58 p√°ginas scrapadas
- 558,342 caracteres de conte√∫do
- 338.9 KB de JSONL
- 100% de taxa de sucesso
- Tempo de execu√ß√£o: ~3 minutos

---

**Vers√£o Inicial** | Projeto limpo e pronto para produ√ß√£o
