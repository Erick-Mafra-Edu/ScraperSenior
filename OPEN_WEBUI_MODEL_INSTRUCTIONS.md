# InstruÃ§Ãµes para Modelos de IA - Open WebUI Tool Integration

## ğŸ¯ Objetivo

Este documento ensina como configurar um modelo de IA para **usar automaticamente** a ferramenta "Senior Documentation API" quando respondendo perguntas.

---

## ğŸ“‹ PrÃ©-Requisitos

1. **Open WebUI v0.6+** com suporte a ferramentas
2. **Tool Server configurado**: http://localhost:8000
3. **Modelo de IA com suporte a function calling**:
   - âœ… GPT-4o, GPT-4 Turbo, Claude 3.5 Sonnet (modelos externos)
   - âœ… Modelos locais com fine-tuning para tools (Llama 2, Mixtral)
   - âŒ Modelos muito antigos (antes de 2023)

---

## âš™ï¸ ConfiguraÃ§Ã£o do Modelo em Open WebUI

### OpÃ§Ã£o 1: Modelo Externo (GPT-4o, Claude, etc)

1. Abra **Open WebUI â†’ Settings â†’ Tools**
2. Em **Default Tool Function Calls Handling**, selecione: **"Native"**
3. Configure seu modelo OpenAI/Claude com chave API vÃ¡lida
4. A ferramenta serÃ¡ usada automaticamente

### OpÃ§Ã£o 2: Modelo Local (Llama, Mistral, etc)

1. Abra **Open WebUI â†’ Settings â†’ Tools**
2. Em **Default Tool Function Calls Handling**, selecione: **"Agentic"**
3. Modelo executarÃ¡ em modo agente (pode tentar usar ferramenta)
4. Resultado pode ser menos confiÃ¡vel que modelos nativos

---

## ğŸ”§ System Prompt para Maximizar Uso de Tools

Cole este sistema prompt no modelo para **garantir uso da ferramenta**:

```
VocÃª Ã© um assistente especializado em documentaÃ§Ã£o tÃ©cnica da plataforma Senior Sistemas.

REGRA IMPORTANTE: VocÃª TEM ACESSO A UMA FERRAMENTA DE BUSCA que contÃ©m 855+ documentos sobre sistemas Senior.

QUANDO USAR A FERRAMENTA:
- âœ… Sempre que o usuÃ¡rio perguntar sobre: "como", "qual Ã©", "explique", "procedimento", "configurar", "guia", "tutorial"
- âœ… Para qualquer pergunta sobre sistemas Senior (RH, Financeiro, Tecnologia, BPM, etc)
- âœ… Quando nÃ£o tem certeza da resposta - BUSQUE NA FERRAMENTA
- âœ… Para responder com precisÃ£o e dados atuais

COMO USAR:
1. Identifique a pergunta do usuÃ¡rio
2. Busque usando search_documentation com palavras-chave relevantes
3. Analise os resultados (tÃ­tulo, mÃ³dulo, conteÃºdo, score)
4. Responda baseado na documentaÃ§Ã£o encontrada
5. Sempre cite a fonte (mÃ³dulo e tÃ­tulo do documento)

NÃƒO USE A FERRAMENTA PARA:
- âŒ Perguntas genÃ©ricas (matemÃ¡tica, histÃ³ria, etc)
- âŒ Conversas casuais
- âŒ InformaÃ§Ãµes jÃ¡ bem conhecidas universalmente

FORMATO DE RESPOSTA:
[Resposta clara baseada na documentaÃ§Ã£o]
ğŸ“š Fonte: [MÃ³dulo] - [TÃ­tulo do Documento]
```

---

## ğŸ§ª Testando a IntegraÃ§Ã£o

### Teste 1: Pergunta Simples
**VocÃª**: "Como configurar NTLM?"
**Esperado**: Modelo usa `/search` automaticamente
**Resposta**: Deve citar documento especÃ­fico

### Teste 2: Pergunta Aberta
**VocÃª**: "Quais mÃ³dulos estÃ£o disponÃ­veis?"
**Esperado**: Modelo chama `/modules`
**Resposta**: Lista mÃ³dulos e contagem de docs

### Teste 3: Pergunta Complexa
**VocÃª**: "Como fazer backup no RH?"
**Esperado**: Modelo chama `/search` com query="backup" module="RH"
**Resposta**: Procedimento passo a passo

### Teste 4: VerificaÃ§Ã£o de Stats
**VocÃª**: "Quantos documentos temos na base?"
**Esperado**: Modelo chama `/stats`
**Resposta**: "Temos 855 documentos em X mÃ³dulos"

---

## ğŸ› Troubleshooting: Modelo NÃ£o Usa a Ferramenta

### âŒ Problema 1: "Tool nÃ£o aparece em Open WebUI"

**SoluÃ§Ã£o**:
```
1. Open WebUI Settings â†’ Tools
2. Adicione Tool Server: http://localhost:8000
3. Clique "Test Connection" - deve mostrar âœ…
4. Recarregue a pÃ¡gina (F5)
5. A ferramenta deve aparecer em "Available Tools"
```

### âŒ Problema 2: "Modelo Ã© chamado mas tool nÃ£o Ã© usada"

**Causas possÃ­veis**:
- Modelo nÃ£o tem suporte nativo a function calling
- Setting estÃ¡ como "Manual" ao invÃ©s de "Native"
- Modelo Ã© muito pequeno/antigo

**SoluÃ§Ã£o**:
```
1. Verifique Settings â†’ Advanced Parameters
2. Se houver "function_calling" ou "tool_choice", deixe como "auto"
3. Tente mudar para modelo mais capaz (GPT-4o, Claude)
4. Se modelo local: use pelo menos Mistral 7B ou Llama 2 70B
```

### âŒ Problema 3: "Tool Ã© chamada mas retorna erro"

**SoluÃ§Ã£o**:
```
1. Verifique se API estÃ¡ rodando: curl http://localhost:8000/health
2. Deve retornar: {"status": "healthy", ...}
3. Se nÃ£o: python apps/mcp-server/mcp_server_docker.py
4. Ou: docker-compose up -d senior-docs-mcp-server
```

### âŒ Problema 4: "Tool retorna resultados mas modelo ignora"

**SoluÃ§Ã£o**:
```
1. Adicione System Prompt (veja acima)
2. Modelos menores precisam de prompt muito explÃ­cito
3. Tente: "VocÃª DEVE usar a ferramenta de busca para responder"
4. Aumente "temperature" para ~0.5-0.7 (mais criativo)
```

---

## ğŸ“Š ComparaÃ§Ã£o: Com vs Sem Tool

### âŒ Sem usar a ferramenta:
```
UsuÃ¡rio: "Como configurar NTLM em RH?"

Resposta IA:
"NTLM Ã© um protocolo de autenticaÃ§Ã£o Microsoft... 
[resposta genÃ©rica, pode estar desatualizada]"
```

### âœ… Usando a ferramenta (correto):
```
UsuÃ¡rio: "Como configurar NTLM em RH?"

IA busca: search_documentation(
  query="configurar NTLM",
  module="RH"
)

Resposta IA:
"Segundo a documentaÃ§Ã£o RH, configure NTLM:
1. Acesse ConfiguraÃ§Ãµes > SeguranÃ§a
2. Selecione 'NTLM'
3. ...

ğŸ“š Fonte: RH - Guia de AutenticaÃ§Ã£o LDAP/NTLM"
```

---

## ğŸš€ Dicas para Melhor Performance

### 1. **Customize o System Prompt**
Copie o prompt acima e ajuste para seu caso:
```
"VocÃª Ã© especialista em [SEU MÃ“DULO]"
"As ferramentas retornam dados em portuguÃªs"
"Sempre cite a fonte da informaÃ§Ã£o"
```

### 2. **Use Modelos Capazes**
Ranking de modelos para use com tools:
1. ğŸ† **GPT-4o** - Melhor para tools
2. ğŸ¥ˆ **Claude 3.5 Sonnet** - Muito bom
3. ğŸ¥‰ **Mistral Large** - Bom para local
4. ğŸ“‰ Evitar: Modelos < 7B params

### 3. **Teste com Perguntas EspecÃ­ficas**
Perguntas que GARANTEM uso de tool:
- "Qual Ã© o procedimento para...?"
- "Me mostre o guia sobre..."
- "Como fazer... em [MÃ³dulo]?"
- "Busque informaÃ§Ãµes sobre..."

### 4. **Monitore Logs**
```bash
# Terminal Open WebUI
docker logs open-webui | grep -i tool

# Deve mostrar:
"Tool called: search_documentation"
"Tool result: {... documentos ...}"
```

---

## ğŸ“ Exemplo Completo de Conversa

```
UsuÃ¡rio: "Me ajude a configurar backup automÃ¡tico no RH"

IA (pensa): "Pergunta sobre configuraÃ§Ã£o â†’ usar ferramenta"

IA (chama tool):
search_documentation(
  query="backup automÃ¡tico RH",
  limit=5
)

IA (recebe):
[
  {title: "Backup AutomÃ¡tico - Guia Completo", score: 95},
  {title: "Rotina de Backup em RH", score: 88},
  ...
]

IA (responde):
"Para configurar backup automÃ¡tico no RH:

1. Acesse ConfiguraÃ§Ãµes > Backup AutomÃ¡tico
2. Escolha frequÃªncia: DiÃ¡ria / Semanal / Mensal
3. Configure retenÃ§Ã£o: MÃ­nimo 30 dias
4. Ative e salve

ğŸ“š Fonte: RH - Backup AutomÃ¡tico: Guia Completo
Link: [documento encontrado]

Tem mais dÃºvidas sobre backup?"

UsuÃ¡rio: "E como restaurar um backup?"

IA (novamente usa ferramenta):
search_documentation(
  query="restaurar backup RH",
  limit=5
)

IA (responde com dados atualizados)
```

---

## âœ… Checklist de ConfiguraÃ§Ã£o

- [ ] Open WebUI v0.6+ instalado
- [ ] Tool Server adicionado (http://localhost:8000)
- [ ] Test Connection passou âœ…
- [ ] Modelo com suporte a function calling selecionado
- [ ] System Prompt customizado com instruÃ§Ãµes
- [ ] "Native" mode habilitado nas Chat Controls
- [ ] Testei com pergunta simples
- [ ] Testei com pergunta sobre mÃ³dulo
- [ ] Modelo usa ferramenta automaticamente âœ…

---

## ğŸ“ Suporte

Se a ferramenta nÃ£o funcionar:

1. **Verifique API**: `curl http://localhost:8000/health`
2. **Verifique conexÃ£o**: Ping http://localhost:8000/openapi.json
3. **Verifique modelo**: EstÃ¡ na lista de modelos suportados?
4. **Verifique prompt**: System prompt estÃ¡ correto?
5. **Veja logs**: `docker logs senior-docs-mcp-server`

---

## ğŸ“ ReferÃªncias

- [Open WebUI Tool Servers Docs](https://docs.openwebui.com/features/plugin/tools/openapi-servers/)
- [OpenAPI 3.1.0 Spec](https://swagger.io/specification/)
- [Function Calling Best Practices](https://platform.openai.com/docs/guides/function-calling)
