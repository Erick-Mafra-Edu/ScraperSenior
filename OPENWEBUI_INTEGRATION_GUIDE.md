# Como Integrar as Tools ao Open WebUI

## 1. Prepara√ß√£o

### Verificar que o servidor MCP est√° rodando:
```bash
curl http://localhost:8000/health
```

Deve retornar:
```json
{
  "status": "ok",
  "timestamp": "..."
}
```

---

## 2. Adicionar as Tools no Open WebUI

### Op√ß√£o A: Via Python (Recomendado)

1. **Copie o arquivo `openwebui_senior_tools.py` para o container/servidor do Open WebUI**

2. **No Open WebUI, v√° para: Settings ‚Üí Tools**

3. **Crie uma nova ferramenta Python com o seguinte c√≥digo:**

```python
# Importe do arquivo que voc√™ copiou
from openwebui_senior_tools import Tools

# Instancie as tools
tools = Tools()

# Defina as fun√ß√µes que o OpenWebUI pode chamar:

async def search_documentation(query: str, module: str = None, strategy: str = "auto", limit: int = 5) -> str:
    """Busca na documenta√ß√£o Senior"""
    return await tools.consultar_documentacao_senior(query, module, strategy, limit)

async def list_modules() -> str:
    """Lista todos os m√≥dulos de documenta√ß√£o"""
    return await tools.listar_todos_modulos()

async def get_module_docs(module_name: str, limit: int = 20) -> str:
    """Obt√©m documentos de um m√≥dulo espec√≠fico"""
    return await tools.consultar_modulo_especifico(module_name, limit)

async def get_stats() -> str:
    """Obt√©m estat√≠sticas da base de documenta√ß√£o"""
    return await tools.obter_estatisticas_base()

async def get_full_document(document_id: str) -> str:
    """Recupera o conte√∫do completo de um documento"""
    return await tools.recuperar_documento_completo(document_id)
```

### Op√ß√£o B: Via REST/OpenAPI

1. **No Open WebUI, v√° para: Settings ‚Üí Tools**

2. **Crie uma ferramenta customizada com os endpoints:**

```
Base URL: http://host.docker.internal:8000/api
```

**Endpoints:**
- `GET /search?query=...&limit=5&strategy=auto` - Buscar
- `GET /modules` - Listar m√≥dulos
- `GET /modules/{module_name}?limit=20` - Docs do m√≥dulo
- `GET /stats` - Estat√≠sticas

---

## 3. Usar as Tools em Conversas

### Exemplo 1: Perguntar sobre LSP
```
Usu√°rio: "Como configurar LSP no Senior?"
LLM: Usa tool `search_documentation` com query="configurar LSP"
Resposta: Retorna documentos sobre LSP
```

### Exemplo 2: Explorar m√≥dulos
```
Usu√°rio: "Quais m√≥dulos de documenta√ß√£o voc√™ tem?"
LLM: Usa tool `list_modules`
Resposta: Lista todos os m√≥dulos dispon√≠veis
```

### Exemplo 3: Busca com contexto
```
Usu√°rio: "Sobre implanta√ß√£o no RH"
LLM: Usa tool `search_documentation` com query="implanta√ß√£o", module="RH"
Resposta: Documentos espec√≠ficos do RH
```

---

## 4. Configura√ß√£o do Host

### Se O Open WebUI est√° no Docker:
```python
# openwebui_senior_tools.py
self.base_url = "http://host.docker.internal:8000"
```

### Se Open WebUI est√° local (sem Docker):
```python
# openwebui_senior_tools.py
self.base_url = "http://localhost:8000"
```

### Se est√° em rede remota:
```python
# openwebui_senior_tools.py
self.base_url = "http://people-fy.com:8000"
```

---

## 5. System Prompt Recomendado

Use este system prompt para direcionar o LLM a usar as tools:

```
Voc√™ √© um assistente que responde perguntas sobre a documenta√ß√£o t√©cnica da Senior.

Quando o usu√°rio fizer uma pergunta:
1. Use a ferramenta `search_documentation` para buscar informa√ß√µes relevantes
2. Se precisar explorar m√≥dulos, use `list_modules` ou `get_module_docs`
3. Se a resposta inicial for insuficiente, use `get_full_document` para mais detalhes
4. Sintetize as informa√ß√µes e responda ao usu√°rio em portugu√™s

Lembre-se:
- "LSP" = Linguagem Senior de Programa√ß√£o
- Sempre cite a fonte (m√≥dulo e documento)
- Se n√£o encontrar, sugira buscar em outro m√≥dulo
- Use `get_stats` para informar sobre a base quando perguntado
```

---

## 6. Teste Local (Sem Open WebUI)

Execute o script de teste:
```bash
python openwebui_senior_tools.py
```

Deve mostrar:
```
1Ô∏è‚É£ Buscando 'LSP'...
### üìö Resultados para: 'LSP'
...

2Ô∏è‚É£ Listando m√≥dulos...
### üìö M√≥dulos de Documenta√ß√£o Dispon√≠veis
...
```

---

## 7. Resolu√ß√£o de Problemas

### "Connection refused" ou "timeout"
- Verifique se o servidor MCP est√° rodando na porta 8000
- Teste: `curl http://localhost:8000/health`

### "Module not found" ou erro de import
- Certifique-se que `openwebui_senior_tools.py` est√° no PYTHONPATH
- Se em Docker, copie o arquivo para dentro do container

### Respostas gen√©ricas demais
- Tente usar a estrat√©gia `"quoted"` para buscas de frases exatas
- Use `strategy="and"` para garantir que todos os termos estejam presentes

### Documento n√£o encontrado com `get_full_document`
- Verifique se o `document_id` vem dos resultados de busca
- Alguns documentos podem ter apenas resumo dispon√≠vel

---

## 8. Estrutura de Resposta (Para Refer√™ncia)

### /api/search
```json
{
  "status": "success",
  "query": "LSP",
  "parsed_query": "\"LSP\"",
  "strategy": "auto",
  "count": 5,
  "results": [
    {
      "title": "...",
      "url": "...",
      "module": "...",
      "content": "..."
    }
  ]
}
```

### /api/modules
```json
{
  "status": "success",
  "total_modules": 12,
  "modules": ["Help Center", "Release Notes", ...]
}
```

### /api/stats
```json
{
  "status": "success",
  "data": {
    "total_documents": 10456,
    "total_modules": 12,
    "indexed_date": "2026-02-05",
    "index_size": "45.3 MB"
  }
}
```

---

## 9. Dicas para Melhor Performance

1. **Cache**: Open WebUI faz cache de respostas. Respostas iguais s√£o devolvidas mais r√°pido
2. **Limite**: Use `limit=5` para buscas r√°pidas, `limit=20+` para listagens completas
3. **Estrat√©gia**: 
   - Use `"auto"` por padr√£o (inteligente)
   - Use `"quoted"` para frases exatas
   - Use `"and"` para garantir m√∫ltiplos termos
4. **Contexto**: Sempre passe `module` quando souber em qual m√≥dulo buscar

---

## 10. Pr√≥ximos Passos

- Monitore os logs do servidor MCP para ver quais queries est√£o sendo feitas
- Refine o system prompt baseado no comportamento do LLM
- Considere adicionar mecanismos de feedback (thumbs up/down) para melhorar o ranking
